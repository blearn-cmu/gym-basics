{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Cab\n",
    "\n",
    "[Taxi](https://gym.openai.com/envs/Taxi-v2/) is one of the environments in the gym toolkit. It is a simulation of a self-driving taxicab in a simplified environment (a 5x5 grid).\n",
    "\n",
    "There are 4 locations (labeled by different letters) and the Taxi's job is to pick up the passenger at one location and drop her off in another.\n",
    "\n",
    "We also want the taxi to:\n",
    "* Drop off passengers at the right location\n",
    "* Deliver the passenger as fast as possible\n",
    "* Take care of the passenger and follow traffic rules\n",
    "\n",
    "To model this as a reinforcement learning solution we'll need to consider: **rewards**, **states**, and **actions**.\n",
    "\n",
    "Recall the learning process for reinforcement learning:\n",
    "1. Observation of the environment\n",
    "2. Deciding how to act\n",
    "3. Acting accordingly\n",
    "4. Receiving a reward or penalty\n",
    "5. Learning from experiences and refining strategy\n",
    "6. Iterate until optimal strategy is found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rewards\n",
    "\n",
    "Since the **agent** (the Taxi) learning from rewards, we need to understand how the environment rewards and/or penalizes the agent.\n",
    "* The agent receives a high positive reward for a successful dropoff: +20 points\n",
    "* The agent gets a slight negative reward for not making it to the destination every time-step: -1 point\n",
    "* The agent is penalized if it tries to drop-off a passenger in the wrong location: -10 points\n",
    "\n",
    "Luckily, the gym environment takes care of when the agent receives rewards/penalties and how much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. State Space\n",
    "\n",
    "The **State Space**  is is the set of all possible situations the taxi could be in. The state contains useful information the agent needs to make the right action.\n",
    "\n",
    "In this environment we have a 5x5 grid, giving us 25 locations the taxi can inhabit. These 25 locations are part of the **State Space**.\n",
    "\n",
    "Let's take a look at an example of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35m\u001b[34;1mR\u001b[0m\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make(\"Taxi-v2\").env\n",
    "env.s = 240\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just one state of the State Space.\n",
    "\n",
    "We also have four different locations (R, G, Y, B), these are the drop-off locations. \n",
    "\n",
    "In this example state, the Passenger is a drop-off Y (the Passenger location turns purple). The Passenger can be at any of the four drop-off locations or in the taxi, giving her five possible locations.\n",
    "\n",
    "These four drop-off locations and five Passenger locations are part of the State Space as well. In total the taxi environment has, **5 x 5 x 5 x 4 = 500** total possible states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Action Space\n",
    "\n",
    "The agent encounters one of the 500 states and it takes an action. The action in our case can be to move in a direction or decide to pickup/dropoff a passenger.\n",
    "\n",
    "In other words, we have **six possible actions**:\n",
    "0. south\n",
    "1. north\n",
    "2. east\n",
    "3. west\n",
    "4. pickup\n",
    "5. dropoff\n",
    "\n",
    "This is the **Action Space**: the set of all the actions that our agent can take in a given state.\n",
    "\n",
    "Note that the environment also contains walls (represented by the **pipe**, \"|\"). In the environment's code, it will simply provide a -1 penalty for every wall hit and the taxi won't move anywhere. This will rack up penalties causing the taxi to consider going around the wall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Gym's Interface\n",
    "\n",
    "The core gym interface is env, which is the unified environment interface. The following are the env methods that will be helpful:\n",
    "\n",
    "* **env.reset:** Resets the environment and returns a random initial state.\n",
    "* **env.step(action):** Step the environment by one timestep. Returns:\n",
    "  * **observation:** Observations of the environment\n",
    "  * **reward:** If your action was beneficial or not\n",
    "  * **done:** Indicates if we have successfully picked up and dropped off a passenger, also called one episode\n",
    "  * **info:** Additional info such as performance and latency for debugging purposes\n",
    "* **env.render:** Renders one frame of the environment (helpful in visualizing the environment)\n",
    "\n",
    "Note: We are using the .env on the end of make to avoid training stopping at 200 iterations, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | :\u001b[43m \u001b[0m:\u001b[34;1mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"Taxi-v2\").env\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the Action Space and State Space are what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | :\u001b[43m \u001b[0m:\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "\n",
      "Action Space Discrete(6)\n",
      "State Space Discrete(500)\n"
     ]
    }
   ],
   "source": [
    "env.reset() # reset environment to a new, random state\n",
    "env.render()\n",
    "\n",
    "print(\"Action Space {}\".format(env.action_space))\n",
    "print(\"State Space {}\".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RL algorithm won't need any more information than these two things. All we need is a way to identify a state uniquely by assigning a unique number to every possible state, and RL learns to choose an action number from 0-5 where:\n",
    "\n",
    "* 0 = south\n",
    "* 1 = north\n",
    "* 2 = east\n",
    "* 3 = west\n",
    "* 4 = pickup\n",
    "* 5 = dropoff\n",
    "\n",
    "Recall that the 500 states correspond to a encoding of the Taxi's location, the Passenger's location, and the drop-off location.\n",
    "\n",
    "Reinforcement Learning will learn a mapping of states to the optimal action to perform in that state by exploration, i.e. the agent explores the environment and takes actions based off rewards defined in the environment.\n",
    "\n",
    "The optimal action for each state is the action that has the highest cumulative long-term reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reward Table\n",
    "\n",
    "When the Taxi environment is created, there is an initial Reward table that's also created, called `P`. We can think of it like a matrix that has the number of states as rows and number of actions as columns, i.e. a states × actions matrix.\n",
    "\n",
    "Since every state is in this matrix, we can see the default reward values assigned to our illustration's state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TimeLimit' object has no attribute 'P'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-19d9e8d6042b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TimeLimit' object has no attribute 'P'"
     ]
    }
   ],
   "source": [
    "env.P[240]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary has the structure:\n",
    "\n",
    "```\n",
    "{action: [(probability, nextstate, reward, done)]}\n",
    "```\n",
    "\n",
    "A few things to note:\n",
    "* The 0-5 corresponds to the actions (south, north, east, west, pickup, dropoff) the taxi can perform at our current state.\n",
    "* In this env, probability is always 1.0.\n",
    "* The nextstate is the state we would be in if we take the action at this index of the dict\n",
    "* All the movement actions have a -1 reward and the pickup/dropoff actions have -10 reward in this particular state. If we are in a state where the taxi has a passenger and is on top of the right destination, we would see a reward of 20 at the dropoff action (5)\n",
    "* done is used to tell us when we have successfully dropped off a passenger in the right location. Each successfull dropoff is the end of an episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Without Reinforment Learning: Random Search\n",
    "\n",
    "We can try to brute-force our way to solve the problem without RL. Starting with a random search is a good way to benchmark your solutions.\n",
    "\n",
    "We'll create a loop that runs until one passenger reaches their destination (one episode).\n",
    "\n",
    "Recall from the previous lab that env.action_space.sample() method selects one random action from set of all possible actions. We'll have the agent use this to choose actions.\n",
    "\n",
    "**Note:** Sine we create the environment with \"make(\"Taxi-v2\")\" rather than just \"make(\"Taxi-v2\").env\", it will stop running after 200 timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 200\n",
      "Penalties incurred: 63\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"Taxi-v2\")\n",
    "\n",
    "epochs = 0\n",
    "penalties, reward = 0, 0\n",
    "\n",
    "frames = [] # for animation\n",
    "done = False\n",
    "\n",
    "env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "\n",
    "    if reward == -10:\n",
    "        penalties += 1\n",
    "    \n",
    "    # Put each rendered frame into dict for animation\n",
    "    frames.append({\n",
    "        'frame': env.render(mode='ansi'),\n",
    "        'state': state,\n",
    "        'action': action,\n",
    "        'reward': reward\n",
    "        }\n",
    "    )\n",
    "\n",
    "    epochs += 1\n",
    "    \n",
    "    \n",
    "print(\"Timesteps taken: {}\".format(epochs))\n",
    "print(\"Penalties incurred: {}\".format(penalties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it would be nice to see what the agent is doing, we've stored each frame in the 'frame' list. Let's write a function that can replay these frames for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "def print_frames(frames):\n",
    "    for i, frame in enumerate(frames):\n",
    "        clear_output(wait=True)\n",
    "        print(frame['frame'].getvalue())\n",
    "        print(f\"Timestep: {i + 1}\")\n",
    "        print(f\"State: {frame['state']}\")\n",
    "        print(f\"Action: {frame['action']}\")\n",
    "        print(f\"Reward: {frame['reward']}\")\n",
    "        sleep(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass a list of frames to the print_frames() function to replay an episode.\n",
    "\n",
    "**Note: It may take a while to replay all the frames if the episode took many timesteps. You can stop the cell from running by interrupting the kernel. To do so: Click the stop button; or go to Kernel-> Interrupt **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :\u001b[42mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "\n",
      "Timestep: 200\n",
      "State: 96\n",
      "Action: 2\n",
      "Reward: -1\n"
     ]
    }
   ],
   "source": [
    "print_frames(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a function that can run one episode for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Returns:\n",
    "frames - A list of frames from every timestep\n",
    "epochs - The number of timesteps taken\n",
    "penalties - The total number of penalties received\n",
    "'''\n",
    "def run_episode(env):  \n",
    "    epochs = 0\n",
    "    penalties, reward = 0, 0\n",
    "\n",
    "    frames = [] # for animation\n",
    "    done = False\n",
    "\n",
    "    env.reset()\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        # Put each rendered frame into dict for animation\n",
    "        frames.append({\n",
    "            'frame': env.render(mode='ansi'),\n",
    "            'state': state,\n",
    "            'action': action,\n",
    "            'reward': reward\n",
    "            }\n",
    "        )\n",
    "\n",
    "        epochs += 1\n",
    "\n",
    "    return frames, epochs, penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 4327\n",
      "Penalties incurred: 1433\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Taxi-v2\").env # create environment without 200 timestep cut-off\n",
    "_, timesteps, penalties = run_episode(env)\n",
    "\n",
    "print(\"Timesteps taken: {}\".format(timesteps))\n",
    "print(\"Penalties incurred: {}\".format(penalties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write a random research function so we can more easily evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Returns:\n",
    "timesteps - The number of timesteps taken\n",
    "penalties - The total number of penalties received\n",
    "'''\n",
    "def random_search(num_episodes):\n",
    "    num_episodes = num_episodes\n",
    "    time_list = []\n",
    "    penalty_list = []\n",
    "    \n",
    "    for episodes in range(1, num_episodes+1):\n",
    "        _, timesteps, penalties = run_episode(env)\n",
    "        time_list.append(timesteps)\n",
    "        penalty_list.append(penalties)\n",
    "        \n",
    "    return time_list, penalty_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Random Search\n",
    "\n",
    "Let's start by running random search 100 times. We'll need matplot and numpy for processing and viewing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## %% time is a system call ##\n",
    "## It will display how much time it took to run this code block ##\n",
    "\n",
    "\n",
    "times, penalties = random_search(100)  # Run random_search() 100 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot histograms for timesteps and penalties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAErCAYAAABEuCN1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmRWcGM3MzApOjGZmZgUnRjMzs8L/ByhSwZdUABYaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218bab23eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.hist(times)\n",
    "fig.suptitle('Histogram of Timesteps for Random Search', fontsize=20)\n",
    "plt.xlabel('Episodes required to solve', fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAErCAYAAACozUZjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218bd4ab5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.hist(penalties)\n",
    "fig.suptitle('Histogram of Penalties for Random Search', fontsize=20)\n",
    "plt.xlabel('Episodes required to solve', fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's also calculate the mean values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean timesteps taken: 2062.35\n",
      "Mean penalties incurred: 665.97\n"
     ]
    }
   ],
   "source": [
    "mean_time = np.array(times).mean()\n",
    "mean_penalty = np.array(penalties).mean()\n",
    "\n",
    "print(\"Mean timesteps taken: {}\".format(mean_time))\n",
    "print(\"Mean penalties incurred: {}\".format(mean_penalty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving with RL: Q-Learning\n",
    "\n",
    "Essentially, Q-learning lets the agent use the environment's rewards to learn, over time, the best action to take in a given state.\n",
    "\n",
    "In our Taxi environment, we have the reward table, P, that the agent will learn from. It does thing by looking receiving a reward for taking an action in the current state, then updating a Q-value to remember if that action was beneficial.\n",
    "\n",
    "The values store in the Q-table are called a Q-values, and they map to a (state, action) combination.\n",
    "\n",
    "A Q-value for a particular state-action combination is representative of the \"quality\" of an action taken from that state. Better Q-values imply better chances of getting greater rewards.\n",
    "\n",
    "For example, if the taxi is faced with a state that includes a passenger at its current location, it is highly likely that the Q-value for pickup is higher when compared to other actions, like dropoff or north."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q(state,action)←(1−α)Q(state,action)+α(reward+γmaxaQ(next state,all actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_table = np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100000\n",
      "Training finished.\n",
      "\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"Training the agent\"\"\"\n",
    "\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1\n",
    "\n",
    "# For plotting metrics\n",
    "all_epochs = []\n",
    "all_penalties = []\n",
    "\n",
    "for i in range(1, 100001):\n",
    "    state = env.reset()\n",
    "\n",
    "    epochs, penalties, reward, = 0, 0, 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample() # Explore action space\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) # Exploit learned values\n",
    "\n",
    "        next_state, reward, done, info = env.step(action) \n",
    "        \n",
    "        old_value = q_table[state, action]\n",
    "        next_max = np.max(q_table[next_state])\n",
    "        \n",
    "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "        q_table[state, action] = new_value\n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        state = next_state\n",
    "        epochs += 1\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Episode: {i}\")\n",
    "\n",
    "print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 100 episodes:\n",
      "Average timesteps per episode: 12.53\n",
      "Average penalties per episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
    "\n",
    "total_epochs, total_penalties = 0, 0\n",
    "episodes = 100\n",
    "\n",
    "for _ in range(episodes):\n",
    "    state = env.reset()\n",
    "    epochs, penalties, reward = 0, 0, 0\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = np.argmax(q_table[state])\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        epochs += 1\n",
    "\n",
    "    total_penalties += penalties\n",
    "    total_epochs += epochs\n",
    "\n",
    "print(f\"Results after {episodes} episodes:\")\n",
    "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
    "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your own program\n",
    "\n",
    "Next, I want you to use this code as a reference to write your own program that can solve a different environment: Acrobot-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "[ 0.99839889  0.05656546  0.99998782  0.00493458  0.08323316  0.03488322]\n",
      "Box(6,)\n",
      "Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Acrobot-v1\")\n",
    "\n",
    "observation = env.reset()\n",
    "\n",
    "# Observation: 6 continuous values\n",
    "print(observation)\n",
    "print(env.observation_space)\n",
    "\n",
    "# Actions: 3 discrete values\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
